{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What I want to do: **Play the dogs versus cats competition on kaggle by fine-tuning a pretrained deep learning model, specifically the Vgg16 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Sign up for the dogs v cats comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign up [here](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition). You can actually sign up when you try to make a submission or when you try to download the data. There are 25,000 labelled dog and cat photos available for training, and 12,500 in the test set that we have to try to label for this competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Set up the kaggle cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command line interface for kaggle has been developed by this [fine gentleman](https://github.com/floydwch/kaggle-cli). thank you!\n",
    "\n",
    "In this case, the competition name is \"dogs-vs-cats-redux-kernels-edition\". Also dont forget to globally configure your username and password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter \"kg download\" from the kaggle-cli after creating a separate folder called kaggle_dogscats in your data directory. Note, I'm assuming you're using a large GPU box. Otherwise this will be miserably slow.\n",
    "\n",
    "After you've finished downloading, you'll see a sample file and 2 zip files for test and train. Unzip these latter files to get 2 new directories for test and train\n",
    "\n",
    "unzip test.zip<br\\>\n",
    "unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ls test/ | wc -l   # 12500 images in test set<br>\n",
    "ls train/ | wc -l  # 25000 images in training set\n",
    "\n",
    "ls kaggle_dogscats/train/ | less  <br>\n",
    "ls kaggle_dogscats/train/ | tail   # i see that in the training set, images are in the format  class(dog/cat).image_id(986660).jpg\n",
    "\n",
    "ls kaggle_dogscats/test/ | tail    # in the test set though, images are in the format image_id(986660).jpg<br>\n",
    "\n",
    "ls kaggle_dogscats/train/ | grep 'dog' | wc -l    # 12500 images of dog in the training set<br>\n",
    "ls kaggle_dogscats/train/ | grep 'cat' | wc -l    # 12500 images of cat in the training set\n",
    "\n",
    "so I'll use uniform distribution for shuffling and sampling the training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Split images into training, test, validation and sample sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute \"split_images_into_directories.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from split_images_into_directories import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files were unable to be classified into response classes in the 'train' sub-directory within the 'data/data_kaggle_dogscats/sample' directory\n",
      "0 files were unable to be classified into response classes in the 'valid' sub-directory within the 'data/data_kaggle_dogscats/sample' directory\n",
      "0 files were unable to be classified into response classes in the 'train' sub-directory within the 'data/data_kaggle_dogscats/train' directory\n",
      "0 files were unable to be classified into response classes in the 'valid' sub-directory within the 'data/data_kaggle_dogscats/train' directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_image_dataset_into_train_test_validation_sample(\"data/data_kaggle_dogscats\", \n",
    "                                                       response_classes=['dog','cat'],\n",
    "                                                       perc_split = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process barely took 2 seconds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Test whether the directories are how you want it to be "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually checked whether the file splits are to my satisfaction. It all checks out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "329  clear                                           \n",
    "330  ls data/data_kaggle_dogscats/ | wc -l           \n",
    "331  ls data/data_kaggle_dogscats/                   \n",
    "332  ls data/data_kaggle_dogscats/train | wc -l      \n",
    "333  ls data/data_kaggle_dogscats/test | wc -l       \n",
    "334  head data/data_kaggle_dogscats/train/           \n",
    "335  ls data/data_kaggle_dogscats/train | head       \n",
    "336  ls data/data_kaggle_dogscats/train | tail       \n",
    "337  ls data/data_kaggle_dogscats/                   \n",
    "338  cd data/data_kaggle_dogscats/                   \n",
    "339  ls test | wc -l                                 \n",
    "340  ls sample | wc -l                               \n",
    "341  ls sample/train | wc -l                         \n",
    "342  ls sample/train/dog | wc -l                     \n",
    "343  ls sample/train/cat | wc -l                     \n",
    "344  ls sample/valid/cat | wc -l                     \n",
    "345  ls sample/valid/dog | wc -l                     \n",
    "346  ls train/valid/dog | wc -l                      \n",
    "347  ls valid/dog | wc -l                            \n",
    "348  ls valid/cat | wc -l                            \n",
    "349  ls train/cat | wc -l                            \n",
    "350  ls train/dog | wc -l                            \n",
    "351  history                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: Rewrite the code taught during lesson 1 in the fastai course for the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN. Step 7 onwards will be in another ipynb. I want to logically break here because I'm hungry. Also dont want to run the split image piece of code each time I run the amazon instance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
